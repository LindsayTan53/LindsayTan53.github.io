---
layout: about
title: About
permalink: /
---

# Lindsay Tan

I'm a data science undergraduate with strong interests in machine learning, causal inference, and data visualization. My academic background combines statistical modeling, computational thinking, and applied analytics, with hands-on experience in both structured coursework and independent projects.

At the University of Washington, I have completed courses in statistical learning, portfolio theory, computational finance, and qualitative research. These have equipped me with solid foundations in both theory and application‚Äîranging from bootstrapped estimations in R to Tableau-based dashboard design and causal modeling in Python.

My current research interests include:
- Causal machine learning (e.g., matching methods, ATE/ATT estimation, and DoWhy)
- Data storytelling with Tableau and interactive dashboards
- Real-world applications of interpretable ML in environmental and economic contexts

In the past, I‚Äôve worked on projects involving:
- Predicting survival probabilities using logistic regression and random forests (Kaggle Titanic)
- Building efficient frontier portfolios and computing VaR in R
- Conducting qualitative coding using ATLAS.ti for environmental policy transcripts

I‚Äôm actively seeking opportunities where I can apply my data science skills to solve meaningful problems in research, technology, or policy. I'm especially interested in internships and collaborative research that bridge machine learning and domain expertise.

Feel free to reach out!

---

## üß† Machine Learning Projects

### üêç Titanic Survival Prediction (Kaggle)

- Built a logistic regression and random forest classifier to predict survival using Scikit-learn
- Achieved 81% accuracy on the public leaderboard
- Used feature engineering (age binning, title extraction) to improve model performance  
- [GitHub Repo](https://github.com/lindsaytan/titanic-ml)

---

### üß™ Causal Inference in Marketing Campaigns

- Used DoWhy to simulate and estimate ATT/ATE on customer purchasing behavior
- Applied propensity score matching to eliminate confounding bias
- [Notebook Demo](https://github.com/lindsaytan/causal-marketing)

---

### üìä Tableau Dashboard: Airbnb Data Analysis

- Created interactive dashboards to visualize price trends and reviews across cities
- Used calculated fields, filters, and storytelling mode to highlight insights
- [PDF Screenshot](https://example.com/airbnb-dashboard.pdf)

## üß† Machine Learning Projects

### üè† Predicting Housing Prices with Linear Regression

- Built a linear regression model to predict house prices based on features such as square footage, number of bedrooms, and location indicators.
- Applied one-hot encoding and log-transformation to reduce skewness and improve prediction accuracy.
- Performed train-test split, error evaluation with RMSE, and feature significance analysis.
- Tools used: `pandas`, `scikit-learn`, `matplotlib`
<!-- [View notebook](https://github.com/yourname/housing-price-prediction) -->

---

### üí¨ Sentiment Analysis on Movie Reviews

- Cleaned and preprocessed IMDB movie reviews dataset using TF-IDF and stopword removal.
- Trained and compared logistic regression and Naive Bayes classifiers to predict review sentiment (positive/negative).
- Evaluated model performance with accuracy, precision, and confusion matrices.
- Tools used: `nltk`, `sklearn`, `pandas`, `seaborn`
<!-- [View notebook](https://github.com/yourname/sentiment-analysis) -->

---

### üí≥ Loan Default Prediction with Decision Trees

- Built a decision tree classifier to predict loan safety levels based on applicant features such as credit history, loan amount, and income ratio.
- Visualized decision boundaries and tree structures for model interpretability.
- Performed pruning to mitigate overfitting and tuned `max_depth`, `min_samples_split`, etc.
- Tools used: `sklearn.tree`, `pandas`, `graphviz`
<!-- [View notebook](https://github.com/yourname/loan-safety-decision-tree) -->

---

### üßµ K-Means Clustering on Textual Data

- Applied unsupervised clustering to group similar documents based on their TF-IDF representations.
- Explored vectorization, elbow method for optimal `k`, and used PCA for visualization in 2D.
- Interpreted clusters by analyzing top keywords and matching representative documents.
- Tools used: `scikit-learn`, `TfidfVectorizer`, `PCA`, `matplotlib`
<!-- [View notebook](https://github.com/yourname/kmeans-text) -->

---

## üí° Upcoming

More projects and writing coming soon...
